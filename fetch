#!/usr/bin/env python3

import re
import os
import sys
import json
import logging
from urllib.parse import urlparse
from urllib.request import Request, urlopen

logger = logging.getLogger(__name__)
logging.basicConfig(
    stream=sys.stdout if os.getenv("MERGE_STREAMS") else sys.stderr,
    format='[%(asctime)s] %(levelname)s * %(message)s',
    level=logging.DEBUG if os.getenv("DEBUG") else logging.WARNING)

def load_collections():
    req = Request("https://api.raindrop.io/rest/v1/collections")
    req.add_header("Authorization", f"Bearer {os.environ['RAINDROP_TOKEN']}")

    resp = urlopen(req, timeout=5)
    collections = json.loads(resp.read())
    if "items" not in collections:
        logging.error("failed to fetch raindrop collections")
        sys.exit(1)

    return {x["_id"]: x["title"] for x in collections["items"]}

def load_all_bookmarks(per_page=50, max_pages=1000):
    bookmarks = []

    url = f"https://api.raindrop.io/rest/v1/raindrops/0?perpage={per_page}&page=" + "{}"

    page = 0
    while page < max_pages:
        req = Request(url.format(str(page)))
        req.add_header("Authorization", f"Bearer {os.environ['RAINDROP_TOKEN']}")

        logging.debug(f"loading req={req.full_url}")

        resp = urlopen(req, timeout=5)
        payload = json.loads(resp.read())
        if not payload or "items" not in payload or len(payload["items"]) == 0:
            return bookmarks

        bookmarks += payload["items"]
        logging.debug(f"loaded page={page}, accumulated_count={len(bookmarks)}")

        page += 1

    return bookmarks

if "RAINDROP_TOKEN" not in os.environ or not os.environ["RAINDROP_TOKEN"]:
    logging.error("missing raindrop token")
    sys.exit(1)

per_page = int(os.environ.get("PER_PAGE", "50"))
max_pages = int(os.environ.get("MAX_PAGES", "1000"))

collections = load_collections()
bookmarks = load_all_bookmarks(per_page=per_page, max_pages=max_pages)

if os.environ.get("RAW"):
    print(json.dumps(bookmarks, indent=4))
    sys.exit(0)

items = []

for item in bookmarks:
    if "link" not in item:
        logging.warning(f"no link, item={item}")
        continue

    url = item["link"]
    title = item["title"] if "title" in item else None
    tags = item["tags"] if "tags" in item else None
    note = item["excerpt"] if "excerpt" in item else None

    collection_id = item["collectionId"]
    if collection_id in collections:
        collection = collections[collection_id]
    else:
        collection = None

    tag = " ".join([f"#{x}" for x in tags])

    if tag and collection:
        subtitle = f"[{collection}] {tag} {url}"
    elif collection:
        subtitle = f"[{collection}] {url}"
    elif tag:
        subtitle = f"{tag} {url}"
    else:
        subtitle = url

    parts = urlparse(url)
    queryable_parts = f"{parts.netloc} {parts.path} {parts.params} {parts.query} {parts.fragment}"
    url_parts = " ".join(re.split("\\W", queryable_parts))

    items.append({
        "title": title,
        "subtitle": subtitle,
        "arg": url,
        "match": f"{url} {url_parts} {title} {tag} {note} {collection or ''}"
    })

print(json.dumps({"items": items}))
